<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.79.0" />


<title>A Dive into the Kruskal-Wallis Test and its R Code - A Hugo website</title>
<meta property="og:title" content="A Dive into the Kruskal-Wallis Test and its R Code - A Hugo website">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://www.linkedin.com/in/qilin29/">Linkedin</a></li>
    
    <li><a href="https://twitter.com/home">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">15 min read</span>
    

    <h1 class="article-title">A Dive into the Kruskal-Wallis Test and its R Code</h1>

    
    <span class="article-date">2020-11-27</span>
    

    <div class="article-content">
      
<script src="/2020/11/27/a-dive-into-the-kruskal-wallis-test-and-its-r-code/index_files/header-attrs/header-attrs.js"></script>
<link href="/2020/11/27/a-dive-into-the-kruskal-wallis-test-and-its-r-code/index_files/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/2020/11/27/a-dive-into-the-kruskal-wallis-test-and-its-r-code/index_files/anchor-sections/anchor-sections.js"></script>


<p>This is a post about statistical computing.</p>
<p>In this post, I would like to talk about the following things:</p>
<ul>
<li>introduce the Kruscal_Wallis test</li>
<li>examine how to implement this code in R (<code>stats::kruskal.test</code>, <code>coin::oneway_test</code>, <code>rstatix::kruskal_test</code> is not written in R)</li>
<li>examine how to improve the performance of the R code</li>
</ul>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Let the data consist of <span class="math inline">\(N = \sum_{j=1}^{k}n_{j}\)</span> observations from the jth treatmentm j = 1,2,…k. Then the Kruskal-Wallis test is a test which measures if the medians of j population are the same. The null hypothesis is that there is no difference among the locations, and therefore the different samples can be treated as a single combined sample.</p>
<p>To compute the Kruksal-Wallis statistic H, first combine N observation from the k samples and order them from least to greatest. Let <span class="math inline">\(r_{ij}\)</span> denote the rank of <span class="math inline">\(X_{ij}\)</span> in this joint ranking and set <span class="math display">\[R_{j} = \sum_{i=1}^{n_{j}}\]</span> <span class="math display">\[R_{.j} = \frac{R_j}{n_{j}}\]</span>. <span class="math inline">\(R_{1}\)</span> is the joint ranks received by treament 1 and <span class="math inline">\(R_{.1}\)</span> is the average rank of that group. H is given by <span class="math display">\[H = \frac{12}{N(N+1)}\sum_{j=1}^{k}n_j(R_{.j} - \frac{N+1}{2})^2\]</span>
<span class="math display">\[ = (\frac{12}{N(N+1)} \sum_{n_j}\frac{R_j^2}{n_j}) - 3(N+1)\]</span> where <span class="math inline">\((N+1)/2 = (\sum_{j=1}^{k} \sum_{i=1}^{n_j} r_{ij}/N)\)</span> is the average rank of all.</p>
<p>At alpha level of significance, reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(H \geq h_{\alpha}\)</span>.</p>
<p>A special feature about this test is that it is <em>distribution free</em>. We can determine the critical value <span class="math inline">\(h_0\)</span> and control the probability of falsely rejecting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is true, and the error probability does not depend on the specific form of underlying distribution. The underlying distribution is assumed to be from the same family, with only the <em>location</em> parameter different.</p>
<p>It is important to note that it is assumed that the underlying distributions are different <em>only</em> in locations, which means their scales are assumed to be identical.</p>
</div>
<div id="study-of-the-code" class="section level1">
<h1>Study of the code</h1>
<p>The procedure can be implemented by using the <code>cKW</code> function of the R package <code>NSM3</code>.</p>
<pre class="r"><code>library(NSM3)
print(cKW)</code></pre>
<pre><code>function (alpha, n, method = NA, n.mc = 10000) 
{
    outp &lt;- list()
    outp$stat.name &lt;- &quot;Kruskal-Wallis H&quot;
    if (alpha &gt; 1 || alpha &lt; 0 || class(alpha) != &quot;numeric&quot;) {
        cat(&quot;Error: Check alpha value! \n&quot;)
        return(alpha)
    }
    outp$alpha &lt;- alpha
    outp$n &lt;- n
    outp$n.mc &lt;- n.mc
    N &lt;- sum(n)
    if (is.na(method)) {
        if (factorial(N)/prod(factorial(outp$n)) &lt;= 10000) {
            method &lt;- &quot;Exact&quot;
        }
        if (factorial(N)/prod(factorial(outp$n)) &gt; 10000) {
            method &lt;- &quot;Monte Carlo&quot;
        }
    }
    outp$method &lt;- method
    H.calc &lt;- function(obs.data, k) {
        N &lt;- sum(k)
        tmp &lt;- cumsum(k)
        tmp2 &lt;- cumsum(rank(obs.data))[tmp]
        R.2 &lt;- c(tmp2[1]^2, diff(tmp2)^2)/k
        12/(N^2 + N) * sum(R.2) - 3 * N - 3
    }
    if (outp$method == &quot;Exact&quot;) {
        possible.comb &lt;- multComb(n)
        theor.dist &lt;- round(apply(possible.comb, 1, H.calc, k = n), 
            8)
        cutoff.candidates &lt;- sort(unique(theor.dist))
        upper.calc &lt;- function(cand) {
            mean(cand &lt;= theor.dist)
        }
        upper.tails &lt;- unlist(lapply(cutoff.candidates, upper.calc))
        outp$cutoff.U &lt;- cutoff.candidates[min(which(upper.tails &lt;= 
            alpha))]
        outp$true.alpha.U &lt;- upper.tails[min(which(upper.tails &lt;= 
            alpha))]
    }
    if (outp$method == &quot;Asymptotic&quot;) {
        outp$cutoff.U &lt;- qchisq(1 - alpha, length(n) - 1)
    }
    if (outp$method == &quot;Monte Carlo&quot;) {
        mc.dist &lt;- numeric(n.mc)
        for (i in 1:n.mc) {
            mc.dist[i] &lt;- round(H.calc(sample(1:N), n), 8)
        }
        cutoff.candidates &lt;- sort(unique(mc.dist))
        upper.calc &lt;- function(cand) {
            mean(cand &lt;= mc.dist)
        }
        upper.tails &lt;- unlist(lapply(cutoff.candidates, upper.calc))
        outp$cutoff.U &lt;- cutoff.candidates[min(which(upper.tails &lt;= 
            alpha))]
        outp$true.alpha.U &lt;- upper.tails[min(which(upper.tails &lt;= 
            alpha))]
    }
    class(outp) = &quot;NSM3Ch6c&quot;
    outp
}
&lt;bytecode: 0x55c236ca4bb8&gt;
&lt;environment: namespace:NSM3&gt;</code></pre>
<div id="the-cumsum-trick-to-calculate-subgroup-total" class="section level2">
<h2>The <code>cumsum()</code> trick to calculate subgroup total</h2>
<p>I learn a lot from this elegant yet not-that-easy-to-unpacked way to calculate the H statistics.</p>
<pre class="r"><code>H.calc &lt;- function(obs.data, k) {
        N &lt;- sum(k)
        tmp &lt;- cumsum(k)
        tmp2 &lt;- cumsum(rank(obs.data))[tmp]
        R.2 &lt;- c(tmp2[1]^2, diff(tmp2)^2)/k
        12/(N^2 + N) * sum(R.2) - 3 * N - 3
    }</code></pre>
<p>The function takes in a <em>combined data vector</em> (later turns it into a ranking vector like <code>1 3 5 4 3 6</code>) and a <em>group length vector</em> indicating the lengths of each group, such as <code>2 2 2</code>. The two vectors first tell us that the ranking of observation at that position is the 1st, 3rd, 5th, 4th, … etc and the first 1st and 3rd ranked observations belong to group 1 and the 5th and 4th ranked observations belong to group 2.</p>
<p>Let us go through this step by step, and I will use <code>grp 1</code> to denote group 1:</p>
<pre class="r"><code>data_vec = c(1,3,5,1.2,1.8,95,5.2,5.8) # some data vector
length_vec = c(3,3,2) # obs 1-3 belong to group 1, 4-6 to group 2
# 7-8 to group 2
N = sum(length_vec)
print(N)</code></pre>
<pre><code>[1] 8</code></pre>
<p><code>cumsum(length_vec)</code> tells us where each subgroup ends in the index.</p>
<pre class="r"><code>(cumsum_length_vec &lt;- cumsum(length_vec))</code></pre>
<pre><code>[1] 3 6 8</code></pre>
<p>The data vector is transformed into a ranked vector.</p>
<pre class="r"><code>rank_vec &lt;- rank(data_vec) 
rank_vec</code></pre>
<pre><code>[1] 1 4 5 2 3 8 6 7</code></pre>
<p><code>cumsum()</code> applied on ranked vector tell us the cumulative ranking.</p>
<pre class="r"><code>cumsum_rank_vec &lt;- cumsum(rank_vec) 
cumsum_rank_vec</code></pre>
<pre><code>[1]  1  5 10 12 15 23 29 36</code></pre>
<p>Use the index vector we had, we have the cumulative sum of rankings of <code>grp 1</code>, <code>grp 1 + grp 2</code> and <code>grp 1 + grp 2 + grp 3</code> respectively.</p>
<pre class="r"><code>cumsum_rank_grp &lt;- cumsum_rank_vec[cumsum_length_vec]
cumsum_rank_grp</code></pre>
<pre><code>[1] 10 23 36</code></pre>
<p>Then <code>diff()</code> gives us the cumulative ranking of <code>grp 2</code> and <code>grp 3</code>. Comebine that with that of <code>grp 1</code>:</p>
<pre class="r"><code>c(cumsum_rank_grp[1], 
  diff(cumsum_rank_grp))</code></pre>
<pre><code>[1] 10 13 13</code></pre>
<p>So the average <span class="math inline">\(R_j^2\)</span> value is:</p>
<pre class="r"><code>R.2 &lt;- c(cumsum_rank_grp[1]^2, 
  diff(cumsum_rank_grp)^2) / length_vec 
R.2</code></pre>
<pre><code>[1] 33.3333333333 56.3333333333 84.5000000000</code></pre>
<p>Using the formula, we have</p>
<pre class="r"><code>12/(N^2 + N) * sum(R.2) - 3 * N - 3</code></pre>
<pre><code>[1] 2.02777777778</code></pre>
<p>Simply put, this uses <code>cumsum()</code> on data and <code>cumsum()</code> on group_length vector together to produce <code>cumsum()</code> of subgroups.</p>
<p>The code assume we have a combined data set and a vector indicating the group length. What if we are given several vectors of data instead of a combined data vector? And what if we want to explicitly label which group each observation belong to? We can use the following code:</p>
<pre class="r"><code>g1 &lt;- c(1,15,19) # n_j = 3, j = 1
g2 &lt;- c(2,48,92,55) # n_j = 4, j= 2
g3 &lt;- c(73,23,45,4,28)
g &lt;- list(g1, g2, g3) # combine vectors into a list

g_length &lt;- sapply(g, length) # get length vector
g_vec &lt;- Reduce(c, g) # successively combine list into a single vector</code></pre>
<pre class="r"><code># obtain a list of label vector
g_label_list &lt;- sapply(seq_along(g), 
  function(x) rep(x, times = g_length[x]))
print(g_label_list)</code></pre>
<pre><code>[[1]]
[1] 1 1 1

[[2]]
[1] 2 2 2 2

[[3]]
[1] 3 3 3 3 3</code></pre>
<pre class="r"><code># obtain a label vector
g_label &lt;- Reduce(c, g_label_list)
print(g_label)</code></pre>
<pre><code> [1] 1 1 1 2 2 2 2 3 3 3 3 3</code></pre>
<pre class="r"><code>joint_rank &lt;- 
  list(
    rank = rank(g_vec), 
    label = g_label
  )
joint_rank</code></pre>
<pre><code>$rank
 [1]  1  4  5  2  9 12 10 11  6  8  3  7

$label
 [1] 1 1 1 2 2 2 2 3 3 3 3 3</code></pre>
</div>
<div id="exact-test" class="section level2">
<h2>Exact test</h2>
<p>Next, let us see how to calculate the exact test. (NSM p.207) Under <span class="math inline">\(H_0\)</span>, the underlying distributions from different samples are the same, so the assignment of <span class="math inline">\(n_1, n_2, ...\)</span> ranks to group 1, 2, … is equally likely. That is, the probability of the largest/second largest value should appear in any of <code>grp 1</code>, <code>grp 2</code> … etc with the same probability.</p>
<p>As an example, let k =3, <span class="math display">\[n_1 = n_2 = n_3 = 2\]</span>, <span class="math display">\[A = R^2_1 + R^2_2 + R^2_3\]</span>,<span class="math display">\[ H = \frac{12}{6*7} * A/2 - 3(6+1)\]</span></p>
<p>If <code>grp 1</code> has elements 1, 2 (i.e. The first and second ranked observations are in group 1), <code>grp 2</code> has elements 3,4 and <code>grp 3</code> has elements 5, 6, then A = 179 and H = 4.57. There are six similar permutations so that rank 1 and 2 are in one group, rank 3 and 4 are in one group etc. Why 6 permutation? Because the permutation is on the groups, and 3<em>2</em>1 = 6. There are 90 permutations <code>6!/(2!*2!*2!)</code>in total, thus <span class="math inline">\(P_{0}\{H = 4.57\} = 1 / 15\)</span>. It turns out that <span class="math inline">\(P_{0}\{H = 3.71\} = 2 / 15\)</span>, so the probability under <span class="math inline">\(H_0\)</span> that H is greater than 3.71 is therefore <span class="math inline">\(P\{H \geq 3.71\} = P_{0}\{H = 4.57\} + P_{0}\{H = 3.71\} = 3 / 15 = 0.2\)</span>.</p>
<p>The critical value can be found by using the <code>cKW(alpha, group_size_vector)</code> function.</p>
<pre class="r"><code>library(NSM3)
# cKW(0.0503,c(5,4,5),&quot;Exact&quot;)</code></pre>
<div id="the-multcomb-function" class="section level3">
<h3>The <code>multComb()</code> function</h3>
<p>It turns out that the exact test is extremely slow. Perhaps the biggest bottleneck is the <code>multComb</code> function, which takes a group length vector (e.g. <code>c(2,2,1)</code>) and returns a matrix of <code>N!/(n1!*n2!*...*nk!)</code> rows, where each row represents one possible combination.</p>
<pre class="r"><code>mat1 &lt;- NSM3::multComb(c(2,2,1))
mat1</code></pre>
<pre><code>      [,1] [,2] [,3] [,4] [,5]
 [1,]    1    2    3    4    5
 [2,]    1    2    3    5    4
 [3,]    1    2    4    5    3
 [4,]    1    3    2    4    5
 [5,]    1    3    2    5    4
 [6,]    1    3    4    5    2
 [7,]    1    4    2    3    5
 [8,]    1    4    2    5    3
 [9,]    1    4    3    5    2
[10,]    1    5    2    3    4
[11,]    1    5    2    4    3
[12,]    1    5    3    4    2
[13,]    2    3    1    4    5
[14,]    2    3    1    5    4
[15,]    2    3    4    5    1
[16,]    2    4    1    3    5
[17,]    2    4    1    5    3
[18,]    2    4    3    5    1
[19,]    2    5    1    3    4
[20,]    2    5    1    4    3
[21,]    2    5    3    4    1
[22,]    3    4    1    2    5
[23,]    3    4    1    5    2
[24,]    3    4    2    5    1
[25,]    3    5    1    2    4
[26,]    3    5    1    4    2
[27,]    3    5    2    4    1
[28,]    4    5    1    2    3
[29,]    4    5    1    3    2
[30,]    4    5    2    3    1</code></pre>
<p>The number of rows is similar to the coefficient of a multinomial distribution, because multinomial coefficient is exactly the same thing: taken over all combinations of nonnegative integer indices <span class="math inline">\(n_1\)</span> through <span class="math inline">\(n_k\)</span> such that the sum of all <span class="math inline">\(n_j\)</span> is N.</p>
<p>A <a href="https://stackoverflow.com/questions/5671149/permute-all-unique-enumerations-of-a-vector-in-r">stackoverflow question</a> helped tremendously. In the post, data is <code>dat &lt;- c(1,0,3,4,1,0,0,3,0,4)</code>, and he wants to permute all the unique permutations of a vector, while not counting juxtapositions within subsets of the same element type. So the permutation has <code>factorial(10)</code> permutations but only <code>10!/(2!*2!*4!*2!)</code> unique combination. In other words, there are 10 unique values (just like the ranks) and there are four subgroups.</p>
<pre class="r"><code>factorial(10)/(factorial(2)*factorial(2)*factorial(2)*factorial(4))</code></pre>
<pre><code>[1] 18900</code></pre>
<p>At this point I realize that this is exactly the same problem. While <code>multComp</code> uses <em>ranked</em> data as input vector, this uses <em>labeled</em> data as input vector.</p>
<p>In the stackoverflow post, multiple solutions are provided for this problem. One of them is to use the <code>arrangements</code> package by Randy Lai.</p>
<pre class="r"><code>library(arrangements)
mat &lt;- arrangements::permutations(x = 1:3, freq = c(2,2,1)) 
mat</code></pre>
<pre><code>      [,1] [,2] [,3] [,4] [,5]
 [1,]    1    1    2    2    3
 [2,]    1    1    2    3    2
 [3,]    1    1    3    2    2
 [4,]    1    2    1    2    3
 [5,]    1    2    1    3    2
 [6,]    1    2    2    1    3
 [7,]    1    2    2    3    1
 [8,]    1    2    3    1    2
 [9,]    1    2    3    2    1
[10,]    1    3    1    2    2
[11,]    1    3    2    1    2
[12,]    1    3    2    2    1
[13,]    2    1    1    2    3
[14,]    2    1    1    3    2
[15,]    2    1    2    1    3
[16,]    2    1    2    3    1
[17,]    2    1    3    1    2
[18,]    2    1    3    2    1
[19,]    2    2    1    1    3
[20,]    2    2    1    3    1
[21,]    2    2    3    1    1
[22,]    2    3    1    1    2
[23,]    2    3    1    2    1
[24,]    2    3    2    1    1
[25,]    3    1    1    2    2
[26,]    3    1    2    1    2
[27,]    3    1    2    2    1
[28,]    3    2    1    1    2
[29,]    3    2    1    2    1
[30,]    3    2    2    1    1</code></pre>
<p><code>multComb</code> provides a matrix whose <em>value</em> is the rank and whose <em>column</em> is the group. For <code>multComp</code>, the values (ranks) do not really matter. What matters is how each row is uniquely divided into three groups of <em>columns</em>.</p>
<p><code>permutations</code> return a matrix whose <em>value</em> is the group label and the <em>column</em> is the rank.</p>
<p>Another option provided in the post is <code>RcppAlgos</code>:</p>
<pre class="r"><code>mat2 &lt;- RcppAlgos::permuteGeneral(1:3, freqs = c(2,2,1))
mat2</code></pre>
<pre><code>      [,1] [,2] [,3] [,4] [,5]
 [1,]    1    1    2    2    3
 [2,]    1    1    2    3    2
 [3,]    1    1    3    2    2
 [4,]    1    2    1    2    3
 [5,]    1    2    1    3    2
 [6,]    1    2    2    1    3
 [7,]    1    2    2    3    1
 [8,]    1    2    3    1    2
 [9,]    1    2    3    2    1
[10,]    1    3    1    2    2
[11,]    1    3    2    1    2
[12,]    1    3    2    2    1
[13,]    2    1    1    2    3
[14,]    2    1    1    3    2
[15,]    2    1    2    1    3
[16,]    2    1    2    3    1
[17,]    2    1    3    1    2
[18,]    2    1    3    2    1
[19,]    2    2    1    1    3
[20,]    2    2    1    3    1
[21,]    2    2    3    1    1
[22,]    2    3    1    1    2
[23,]    2    3    1    2    1
[24,]    2    3    2    1    1
[25,]    3    1    1    2    2
[26,]    3    1    2    1    2
[27,]    3    1    2    2    1
[28,]    3    2    1    1    2
[29,]    3    2    1    2    1
[30,]    3    2    2    1    1</code></pre>
<p>The <code>RcppAlgos</code> and <code>arrangement</code> package is much faster than the <code>multComb</code>: the mean is 47.36, 58.14 millisecond compared to 68970.9.</p>
<pre class="r"><code>library(microbenchmark)
set.seed(123)
perf &lt;- microbenchmark(
  NSM3::multComb(c(2,2,2,2)),
  arrangements::permutations(x = 1:4, freq = c(2,2,2,2)),
  RcppAlgos::permuteGeneral(1:3, freqs = c(2,2,2),nThreads = 4)
)
perf</code></pre>
<pre><code>Unit: microseconds
                                                             expr       min
                                    NSM3::multComb(c(2, 2, 2, 2)) 70416.138
        arrangements::permutations(x = 1:4, freq = c(2, 2, 2, 2))    36.259
 RcppAlgos::permuteGeneral(1:3, freqs = c(2, 2, 2), nThreads = 4)    16.185
         lq        mean     median         uq        max neval cld
 73959.6375 78846.43438 76041.4895 81306.1275 134298.688   100   b
    39.8790    57.04877    50.4270    64.5355     98.890   100  a 
    20.7205    41.97631    47.7145    61.1615    106.046   100  a </code></pre>
<p>Let us calculate the R value for one row:</p>
<pre class="r"><code>mat[10,]</code></pre>
<pre><code>[1] 1 3 1 2 2</code></pre>
<pre class="r"><code># We can calculate R1, R2, R3 like this:
print(R1 &lt;- ( sum(which(mat[10,] == 1)) )^2)</code></pre>
<pre><code>[1] 16</code></pre>
<pre class="r"><code>print(R2 &lt;- ( sum(which(mat[10,] == 2)) )^2)</code></pre>
<pre><code>[1] 81</code></pre>
<pre class="r"><code>print(R3 &lt;- ( sum(which(mat[10,] == 3)) )^2)</code></pre>
<pre><code>[1] 4</code></pre>
<pre class="r"><code>print(R &lt;- R1 + R2 + R3)</code></pre>
<pre><code>[1] 101</code></pre>
<pre class="r"><code>print(avg_R &lt;- R / c(2,2,2))</code></pre>
<pre><code>[1] 50.5 50.5 50.5</code></pre>
<p>To calculate using this arrangement, we can use the following code:</p>
<pre class="r"><code>library(magrittr)
k = 3
calc_H &lt;- function(perm_matrix, grp_len_vec){
  k = length(grp_len_vec)
  N = sum(grp_len_vec)
  
  total = rep(0, nrow(perm_matrix))
  for (i in 1:k) {
    # the label matrix make R calculation easy
    s &lt;- purrr::map_dbl(1:nrow(perm_matrix), ~ sum(which(perm_matrix[.x,] == i))^2 / grp_len_vec[i])
    total = total + s
  }
  H = (12 / N / (N+1)) * total - 3*(N+1)
  return(round(H,3))
}</code></pre>
<p>Let us walk through the exact test calculation:</p>
<pre class="r"><code>all_H &lt;- calc_H(mat,c(2,2,2))
print(all_H)</code></pre>
<pre><code> [1]  -9.143  -8.286  -6.857 -10.000  -9.429 -10.286 -10.000  -9.143  -9.429
[10]  -6.571  -7.714  -8.286 -10.286 -10.000 -10.000  -9.429  -9.429  -9.143
[19]  -9.143  -8.286  -6.857  -8.286  -7.714  -6.571  -5.714  -6.571  -6.857
[28]  -6.857  -6.571  -5.714</code></pre>
<p>P(H&gt;= 3.71): proportion of entries with value &gt; 3.71</p>
<pre class="r"><code>print( sum(all_H &gt;= 3.71) / length(all_H) )</code></pre>
<pre><code>[1] 0</code></pre>
<p>All the empirical H statistics can be a cutoff quantile candidate (i.e. <span class="math inline">\(h_0\)</span>, because remember the test reject <span class="math inline">\(H_0\)</span> when H&gt;<span class="math inline">\(h_0\)</span>).</p>
<pre class="r"><code>cutoff_candidate &lt;- sort(unique(all_H))
print(cutoff_candidate)</code></pre>
<pre><code>[1] -10.286 -10.000  -9.429  -9.143  -8.286  -7.714  -6.857  -6.571  -5.714</code></pre>
<p>Calculate proportion of H statistics to the <em>right</em> of each cutoff quantile candidate (i.e upper tail):</p>
<pre class="r"><code>all_upperTail_prob &lt;- 
  sapply(cutoff_candidate, function(x) mean(all_H &gt;= x)) # data &gt; candidate
print(all_upperTail_prob)</code></pre>
<pre><code>[1] 1.0000000000000 0.9333333333333 0.8000000000000 0.6666666666667
[5] 0.5333333333333 0.4000000000000 0.3333333333333 0.2000000000000
[9] 0.0666666666667</code></pre>
<p>Pick <code>alpha</code> alpha = 0.10. The “upper cutoff value” is the <span class="math inline">\(h_0\)</span>, which is upper <span class="math inline">\(\alpha\)</span> quantile for the null.</p>
<pre class="r"><code>outp &lt;- list()
alpha = 0.10</code></pre>
<p>The upper cutoff quantile is <em>the smallest cutoff candidate</em> (i.e <em>with largest upper tail probability</em>) such that its upper tail is still less than alpha.</p>
<pre class="r"><code>indexOf_upper_cutoff &lt;-  min(which(all_upperTail_prob &lt;= alpha))
outp$upper_cutoff &lt;- cutoff_candidate[indexOf_upper_cutoff]
outp$upper_cutoff</code></pre>
<pre><code>[1] -5.714</code></pre>
<p>The true alpha value is the corresponding upper tail probability of that upper cutoff value:</p>
<pre class="r"><code>outp$true_alpha &lt;- all_upperTail_prob[indexOf_upper_cutoff]
outp$true_alpha</code></pre>
<pre><code>[1] 0.0666666666667</code></pre>
<p>The result is the same as <code>cKW</code>.</p>
<pre class="r"><code>b &lt;- cKW(0.1,c(2,2,2),&quot;Exact&quot;)
print(b$cutoff.U)</code></pre>
<pre><code>[1] 4.57142857</code></pre>
<pre class="r"><code>print(b$true.alpha.U)</code></pre>
<pre><code>[1] 0.0666666666667</code></pre>
</div>
</div>
<div id="monte-carlo-method-and-asymptotic-method" class="section level2">
<h2>Monte Carlo method and Asymptotic method</h2>
<p>The <code>Asymptotic</code> option uses the large sample approximation,
which is the <span class="math inline">\(\chi^2\)</span> distribution with degree of freedom equal <code>k - 1</code>.</p>
<p>The <code>Monte Carlo</code> option is where the <code>H_calc()</code> used in <code>NSM3</code> works:
it only needs to draws <code>n.mc</code> times from the permutation of the ranks,
and calculate H from each permutations. The method we used in <code>Exact</code>
option does not work because it is not possible to give a full permutation
index.</p>
</div>
</div>
<div id="revised-code" class="section level1">
<h1>Revised code</h1>
<pre class="r"><code>cKW_revised &lt;- function (alpha, grp_len_vec, method = NA, n.mc = 10000) 
{
    outp &lt;- list()
    outp$stat.name &lt;- &quot;Kruskal-Wallis H&quot;
    if (alpha &gt; 1 || alpha &lt; 0 || class(alpha) != &quot;numeric&quot;) {
        cat(&quot;Error: Check alpha value! \n&quot;)
        return(alpha)
    }
    outp$alpha &lt;- alpha
    outp$grp_len_vec &lt;- grp_len_vec
    outp$n.mc &lt;- n.mc
    outp$k &lt;-  length(grp_len_vec)
    outp$N &lt;-  sum(grp_len_vec)
    if (is.na(method)) {
        if (factorial(N)/prod(factorial(outp$n)) &lt;= 10000) {
            method &lt;- &quot;Exact&quot;
        }
        if (factorial(N)/prod(factorial(outp$n)) &gt; 10000) {
            method &lt;- &quot;Monte Carlo&quot;
        }
    }
    outp$method &lt;- method
    
    calc_H &lt;- function(perm_matrix, grp_len_vec){
      k &lt;-  length(grp_len_vec)
      N &lt;-  sum(grp_len_vec)
      total = rep(0, nrow(perm_matrix))
      for (i in 1:k) {
        s &lt;- purrr::map_dbl(1:nrow(perm_matrix), 
            ~ sum(which(perm_matrix[.x,] == i))^2 / grp_len_vec[i])
        total = total + s
      }
      H = (12 / N / (N+1)) * total - 3*(N+1)
      return(round(H,4))
    }
    
    H_calc &lt;- function(obs.data, grp_len_vec) {
        N &lt;- sum(grp_len_vec)
        grp_index &lt;- cumsum(grp_len_vec)
        cumRank &lt;- cumsum(rank(obs.data))[grp_index]
        R.2 &lt;- c(cumRank[1]^2, diff(cumRank)^2)/grp_len_vec
        H = (12 / N / (N+1)) * sum(R.2) - 3*(N+1)
        return(round(H,4))
    }
    
    calc_stats &lt;- function(H_dist){
      cutoff_candidate &lt;- sort(unique(H_dist))
      all_upperTail_prob &lt;- sapply(cutoff_candidate, 
        function(x) mean(H_dist &gt;= x))
      
      indexOf_upper_cutoff &lt;- min(which(all_upperTail_prob &lt;= alpha))
      outp$upper_cutoff &lt;&lt;- cutoff_candidate[indexOf_upper_cutoff]
      outp$true_alpha &lt;&lt;- all_upperTail_prob[indexOf_upper_cutoff]
    }
    
    obs.stat &lt;- H_calc(obs.data = ,grp_len_vec)
    
    if (outp$method == &quot;Exact&quot;) {
      perm_matrix &lt;- RcppAlgos::permuteGeneral(1:outp$k, 
        freqs = grp_len_vec, Parallel = T)
      
      all_H &lt;- calc_H(perm_matrix,grp_len_vec)
      calc_stats(all_H)
      outp$pvalue &lt;- mean(all_H &gt;= obs.stat)
    }
    
    if (outp$method == &quot;Asymptotic&quot;) {
      outp$upper_cutoff &lt;- qchisq(1 - alpha, outp$k - 1)
      outp$pvalue &lt;- 1 - pchisq(obs.stat, df = outp$k - 1)
    }
    
    if (outp$method == &quot;Monte Carlo&quot;) {
      mc.dist &lt;- 1:n.mc
      
      all_H &lt;- sapply(mc.dist, 
        function(x) H_calc(sample(1:outp$N), grp_len_vec))
      
      calc_stats(all_H)
      outp$pvalue &lt;- mean(all_H &gt;= obs.stat)
    }
    return(outp)
}</code></pre>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

